{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ad57cb",
   "metadata": {},
   "source": [
    "\n",
    "# Week 6 — scRNA‑seq mini‑pipeline (Alevin‑fry → AnnData → Leiden → CellTypist)\n",
    "\n",
    "**Goal:** Fetch raw single‑cell FASTQs, build a compact *splici* reference, quantify with the alevin‑fry (via `simpleaf`) pipeline, load counts into an `AnnData`, cluster with Leiden, then auto‑annotate with CellTypist.  \n",
    "This notebook is designed to be **self‑contained**: it installs its own tools and fetches data at run time.\n",
    "\n",
    "> **Re-run hint:** You can safely re-run the whole notebook. Heavy steps cache to `./week6_data/` and `./week6_work/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32fbba",
   "metadata": {},
   "source": [
    "## 0) Configuration & small helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, subprocess, shutil, textwrap, time, pathlib\n",
    "\n",
    "# Project directories\n",
    "ROOT = pathlib.Path.cwd()\n",
    "DATA = ROOT / \"week6_data\"\n",
    "WORK = ROOT / \"week6_work\"\n",
    "OUT  = ROOT / \"week6_results\"\n",
    "for d in (DATA, WORK, OUT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BOX_FOLDER_URL = \"https://app.box.com/s/lx2xownlrhz3us8496tyu9c4dgade814\"\n",
    "BOX_EXPECTED = {}\n",
    "\n",
    "CHEMISTRY = os.environ.get(\"SC_CHEM\", \"10xv3\")  # \"10xv2\" or \"10xv3\"\n",
    "PERMIT_STRATEGY = os.environ.get(\"SC_PERMIT\", \"auto\")   # e.g., \"expect:1500\" or a path\n",
    "THREADS = int(os.environ.get(\"SC_THREADS\", \"4\"))\n",
    "\n",
    "def sh(cmd, env=None, check=True):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    proc = subprocess.run(cmd, shell=True, env=env, check=check)\n",
    "    return proc.returncode\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"WORK:\", WORK)\n",
    "print(\"OUT:\", OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782430e",
   "metadata": {},
   "source": [
    "\n",
    "## 1) One‑time tool bootstrap (micromamba env)\n",
    "\n",
    "We install a minimal conda env containing the alevin‑fry stack via **micromamba**:\n",
    "- `simpleaf` (wrapper), `alevin-fry`, `piscem` (fast mapper), `salmon` (if needed)\n",
    "- `pyroe`, `scanpy`, `anndata`, `python-igraph`, `leidenalg`, `celltypist`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os, platform, pathlib\n",
    "\n",
    "# MAMBA_DIR = ROOT / \"week6_mamba\"\n",
    "# ENV_NAME  = \"scweek6\"\n",
    "# MICROMAMBA = str(MAMBA_DIR / \"bin\" / \"micromamba\")\n",
    "\n",
    "# def ensure_micromamba():\n",
    "#     if (MAMBA_DIR / \"bin\" / \"micromamba\").exists():\n",
    "#         return\n",
    "#     MAMBA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#     sysname = platform.system().lower()\n",
    "#     arch = \"linux-64\" if sysname == \"linux\" else (\"osx-64\" if platform.machine() == \"x86_64\" else \"osx-arm64\")\n",
    "#     url = f\"https://micro.mamba.pm/api/micromamba/{arch}/latest\"\n",
    "#     sh(f\"curl -Ls {url} | tar -xvj bin/micromamba -C {MAMBA_DIR}\")\n",
    "\n",
    "# def mm(args):\n",
    "#     return sh(f\"{MICROMAMBA} \" + args)\n",
    "\n",
    "# def mmrun(cmd):\n",
    "#     return sh(f\"{MICROMAMBA} run -n {ENV_NAME} bash -lc \"{cmd}\"\")\n",
    "\n",
    "# ensure_micromamba()\n",
    "\n",
    "# # Create env\n",
    "# mm(f\"create -y -n {ENV_NAME} -c conda-forge -c bioconda python=3.11 simpleaf alevin-fry piscem salmon scanpy anndata python-igraph leidenalg celltypist pyroe\")\n",
    "\n",
    "# # Cache dir for simpleaf/alevin-fry\n",
    "# AF_HOME = WORK / \"af_home\"\n",
    "# AF_HOME.mkdir(parents=True, exist_ok=True)\n",
    "# os.environ[\"ALEVIN_FRY_HOME\"] = str(AF_HOME)\n",
    "# mmrun(f\"echo ALEVIN_FRY_HOME={str(AF_HOME)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aed44c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Fetch raw data & reference from Box\n",
    "\n",
    "The notebook will attempt to **direct‑download** the Box folder as a zip using `?download=1`.  \n",
    "If your institution's Box requires authentication, place the files manually under `week6_data/` and re‑run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8da17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, requests, zipfile, io, pathlib\n",
    "\n",
    "def box_download_folder(shared_url, out_dir: pathlib.Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    try_urls = [shared_url, shared_url.rstrip('/') + '?download=1']\n",
    "    last_err = None\n",
    "    for url in try_urls:\n",
    "        try:\n",
    "            print(\"Trying:\", url)\n",
    "            with requests.get(url, allow_redirects=True, stream=True, timeout=60) as r:\n",
    "                r.raise_for_status()\n",
    "                ctype = r.headers.get('Content-Type','')\n",
    "                content = r.content\n",
    "                if content[:2] == b'PK':  # zip\n",
    "                    with zipfile.ZipFile(io.BytesIO(content)) as zf:\n",
    "                        zf.extractall(out_dir)\n",
    "                    print(\"Extracted Box zip to\", out_dir)\n",
    "                    return True\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(\"Download failed:\", e)\n",
    "    print(\"Box auto-download did not succeed. Manually download to\", out_dir)\n",
    "    return False\n",
    "\n",
    "_ = box_download_folder(BOX_FOLDER_URL, DATA)\n",
    "print(\"Contents:\", [p.name for p in Path(DATA).glob('**/*')][:20], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb67551",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Build a *splici* reference index (for USA mode)\n",
    "\n",
    "We build a **spliced + intronic** (*splici*) reference from the provided genome FASTA and GTF, then make a compact **piscem** index via `simpleaf index`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "def find_one(patterns):\n",
    "    for p in patterns:\n",
    "        m = glob.glob(str(DATA / p))\n",
    "        if m:\n",
    "            return m[0]\n",
    "    return None\n",
    "\n",
    "GENOME = find_one([\"*.fa\", \"*.fa.gz\", \"*chr5*.fa*\", \"**/*.fa*\", \"**/*chr5*.fa*\"])\n",
    "GTF    = find_one([\"*.gtf\", \"*.gtf.gz\", \"**/*.gtf*\", \"**/*chr5*.gtf*\"])\n",
    "print(\"GENOME:\", GENOME)\n",
    "print(\"GTF:\", GTF)\n",
    "assert GENOME and GTF, \"Could not find genome FASTA or GTF in week6_data.\"\n",
    "\n",
    "IDX_DIR = WORK / \"splici_index\"\n",
    "IDX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mmrun(f\"export ALEVIN_FRY_HOME={str(AF_HOME)}; ulimit -n 2048; simpleaf index --output {str(IDX_DIR)} --fasta {GENOME} --gtf {GTF} --threads {THREADS}\")\n",
    "print(\"Index ready:\", IDX_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9f62f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Quantify FASTQs with `simpleaf quant`\n",
    "\n",
    "This step scans `week6_data/` for `*_R1_*` and `*_R2_*` FASTQs (recursively), then runs `simpleaf quant` in **cr‑like** resolution and **USA** mode.  \n",
    "If you don't have an explicit whitelist, set no variable (auto) or use `SC_PERMIT=expect:N`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "reads1 = subprocess.check_output([\"bash\",\"-lc\", f\"find -L {DATA} -type f -name '*_R1_*fastq*' | sort | paste -sd, -\"]).decode().strip()\n",
    "reads2 = subprocess.check_output([\"bash\",\"-lc\", f\"find -L {DATA} -type f -name '*_R2_*fastq*' | sort | paste -sd, -\"]).decode().strip()\n",
    "print(\"R1 files:\", reads1)\n",
    "print(\"R2 files:\", reads2)\n",
    "assert reads1 and reads2, \"No FASTQs found under week6_data.\"\n",
    "\n",
    "QUANT_DIR = WORK / \"af_quant_run\"\n",
    "QUANT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "permit_flag = \"--unfiltered-pl\"\n",
    "if isinstance(PERMIT_STRATEGY, str) and PERMIT_STRATEGY.startswith(\"expect:\"):\n",
    "    n = PERMIT_STRATEGY.split(\":\")[1]\n",
    "    permit_flag = f\"--expect-cells {int(n)}\"\n",
    "elif PERMIT_STRATEGY and PERMIT_STRATEGY not in (\"auto\",\"\"):\n",
    "    permit_flag = f\"--permit-list {PERMIT_STRATEGY}\"\n",
    "\n",
    "cmd = f\"\"\"\n",
    "export ALEVIN_FRY_HOME={str(AF_HOME)}\n",
    "ulimit -n 2048\n",
    "simpleaf quant   --reads1 {reads1}   --reads2 {reads2}   --threads {THREADS}   --index {str(IDX_DIR)}/index   --chemistry {CHEMISTRY} --resolution cr-like   {permit_flag} --anndata-out   --output {str(QUANT_DIR)}\n",
    "\"\"\"\n",
    "mmrun(cmd)\n",
    "print(\"Quantification done ->\", QUANT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b5a2a",
   "metadata": {},
   "source": [
    "## 5) Load counts into `AnnData` and do basic QC/normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scanpy as sc, anndata as ad, numpy as np, pandas as pd, matplotlib.pyplot as plt, pathlib\n",
    "\n",
    "H5AD = QUANT_DIR / \"af_quant\" / \"quants.h5ad\"\n",
    "assert H5AD.exists(), f\"Missing {H5AD} — check the quant step logs.\"\n",
    "adata = sc.read_h5ad(H5AD)\n",
    "adata.var_names_make_unique()\n",
    "\n",
    "if \"feature_name\" in adata.var.columns:\n",
    "    gene_symbols = adata.var[\"feature_name\"]\n",
    "else:\n",
    "    gene_symbols = adata.var_names\n",
    "\n",
    "adata.var[\"mt\"] = gene_symbols.str.upper().str.startswith((\"MT-\",\"MT_\"))\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "sc.pp.filter_cells(adata, min_counts=500)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=3000, subset=True)\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, n_comps=50, svd_solver=\"arpack\")\n",
    "\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)\n",
    "sc.tl.umap(adata, min_dist=0.3)\n",
    "sc.tl.leiden(adata, key_added=\"leiden_0p5\", resolution=0.5)\n",
    "\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "adata.write(OUT / \"week6_preannot.h5ad\", compression=\"gzip\")\n",
    "adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15750d",
   "metadata": {},
   "source": [
    "## 6) Clustering plot (UMAP colored by Leiden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ed1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scanpy as sc\n",
    "sc.pl.umap(adata, color=[\"leiden_0p5\"], wspace=0.4, show=True, save=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc515f6",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Automatic cell annotation with CellTypist\n",
    "\n",
    "We download a CellTypist model and annotate cells; labels are added to `adata.obs` and plotted on UMAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import celltypist\n",
    "from celltypist import models\n",
    "\n",
    "try:\n",
    "    models.download_models(\"Immune_All_Low\")\n",
    "    model_path = models.models_path() / \"Immune_All_Low.pkl\"\n",
    "except Exception as e:\n",
    "    print(\"Model download issue:\", e)\n",
    "    model_path = None\n",
    "\n",
    "pred = celltypist.annotate(adata, model=str(model_path) if model_path else \"Immune_All_Low.pkl\", majority_voting=True)\n",
    "adata.obs[\"celltypist_label\"] = pred.predicted_labels\n",
    "\n",
    "import scanpy as sc\n",
    "sc.pl.umap(adata, color=[\"celltypist_label\"], legend_loc=\"on data\", legend_fontsize=8, frameon=False, show=True, save=None)\n",
    "\n",
    "adata.write(OUT / \"week6_annotated.h5ad\", compression=\"gzip\")\n",
    "print(\"Saved:\", OUT / \"week6_annotated.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56f526",
   "metadata": {},
   "source": [
    "## 8) Export summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c20132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "sizes = adata.obs[\"leiden_0p5\"].value_counts().sort_index()\n",
    "sizes.to_csv(OUT / \"cluster_sizes.csv\")\n",
    "ct_sizes = adata.obs[\"celltypist_label\"].value_counts()\n",
    "ct_sizes.to_csv(OUT / \"celltypist_counts.csv\")\n",
    "print(\"Wrote:\", OUT / \"cluster_sizes.csv\", \"and\", OUT / \"celltypist_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7224f5",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Notes & FAQ\n",
    "\n",
    "- **Whitelist barcodes link is broken — can we proceed?** Yes. The pipeline can infer a permit list automatically (`--unfiltered-pl`), or you can set an expected cell count via `SC_PERMIT=expect:1500`. If you later obtain a whitelist, set `SC_PERMIT=/path/to/permit_list.txt` and re-run the quant step.\n",
    "- **Chemistry**: Default is `10xv3`. If your data is v2, set `SC_CHEM=10xv2` before executing.\n",
    "- **Re-running**: Index and quants use `week6_work/` and will be reused if present.\n",
    "- **Submission**: Commit only `week6/week6.ipynb`. The notebook fetches/install tools and data during execution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scweek6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
