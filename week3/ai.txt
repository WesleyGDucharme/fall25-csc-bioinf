LLM model used: ChatGPT 
Version: GPT-5

This ai.txt will be very similar to prior descriptions, as I used it in pretty much the same way.

Prompts and Topics:
Throughout my work on deliverable 3 I used ChatGPT to:
- Explain what biotite and give a overview of the parts that I will be porting.
- Used it to help isolate the tests that we are focusing on.
- Used it to help determine what coder to isolate and port to make these tests pass.

- Debugging help.
  * Ex: After every file had its initial ported version I would often get errors after running them on the tests and would use the LLM to help trace and solve errors faster if I was struggling to make a fix.

- Getting guidance on making code Codon-compatible.
  * Tried to deal with class type conflicts again but was alot quicker to fix this time due to my prior experience with this problem in deliverable 2.

- Write automation scripts for testing and evaluation.
  * Ex: Had it help me make the evaluate.sh file which ran the tests on both the codon and python version of the tests that output test completion time.
- Helped with busy work.
 * Documenttation and commented function labels were done by the LLM to help save time.

Notes:
- I edited and ran all code locally to verify correctness.
- AI suggestions were adapted and integrated into my own implementation unless a version the ai suggested worked really well the first time.
- Not all outputs from ChatGPT were used directly â€” in some cases I rolled back to earlier versions or of course ignored the answers and solution prototypes that I knew were wrong or would not work.
