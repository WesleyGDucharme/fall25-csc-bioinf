# Port of Decomposer.refine() â€” pure string logic, no NumPy.

# Given rows where each row is "motif1,motif2,...", return refined rows
# using the same algorithm as Python:
# - Count all adjacent motif pairs (as tuples) across TRs
# - Also count by concatenated string to group ambiguous splits
# - For each adjacent pair (a,b), if there exist multiple motif pairs
#   whose concatenation equals a+b, replace (a,b) with the most frequent
#   pair among that group.

def _split_csv_row(s: str):
    # split by ',' (no quoting in our data)
    out = []
    start = 0
    i = 0
    while i <= len(s):
        if i == len(s) or s[i] == ',':
            out.append(s[start:i])
            start = i + 1
        i += 1
    return out

def _join_csv_row(items: List[str]):
    if len(items) == 0:
        return ""
    # join with ','
    res = items[0]
    i = 1
    while i < len(items):
        res += ","
        res += items[i]
        i += 1
    return res

def refine_pairs(rows):  # no type annotations to keep Codon happy
    # --- parse rows into list[list[str]] ---
    trs = []
    r = 0
    while r < len(rows):
        row = rows[r].strip()
        if len(row) == 0:
            trs.append([])
        else:
            trs.append(_split_csv_row(row))
        r += 1

    # --- build counters (string keys, no .get) ---
    # pair_count: "a\tb" -> int
    pair_count = {}
    # concat_count: "ab" -> int
    concat_count = {}
    # concat_to_pairs: "ab" -> List["a\tb"] (unique)
    concat_to_pairs = {}

    t = 0
    while t < len(trs):
        tr = trs[t]
        i = 0
        while i + 1 < len(tr):
            a = tr[i]
            b = tr[i + 1]
            pkey = a + "\t" + b
            ckey = a + b

            # pair_count[pkey] += 1
            if pkey in pair_count:
                pair_count[pkey] = pair_count[pkey] + 1
            else:
                pair_count[pkey] = 1

            # concat_count[ckey] += 1
            if ckey in concat_count:
                concat_count[ckey] = concat_count[ckey] + 1
            else:
                concat_count[ckey] = 1

            # concat_to_pairs[ckey] contains unique pkeys
            if ckey in concat_to_pairs:
                plist = concat_to_pairs[ckey]
            else:
                plist = []
                concat_to_pairs[ckey] = plist

            # ensure uniqueness
            seen = False
            j = 0
            while j < len(plist):
                if plist[j] == pkey:
                    seen = True
                    break
                j += 1
            if not seen:
                plist.append(pkey)

            i += 1
        t += 1

    # --- refine each TR in place (single pass) ---
    t = 0
    while t < len(trs):
        tr = trs[t]
        i = 0
        while i + 1 < len(tr):
            a = tr[i]
            b = tr[i + 1]
            pkey = a + "\t" + b
            ckey = a + b

            cnt = pair_count[pkey] if (pkey in pair_count) else 0
            if cnt == 0:
                i += 1
                continue

            if (ckey in concat_count) and (cnt < concat_count[ckey]):
                max_key = pkey
                max_cnt = cnt

                if ckey in concat_to_pairs:
                    plist = concat_to_pairs[ckey]
                    j = 0
                    while j < len(plist):
                        cand = plist[j]
                        cval = pair_count[cand] if (cand in pair_count) else 0
                        if cval > max_cnt:
                            max_cnt = cval
                            max_key = cand
                        j += 1

                # split "x\ty" into two motifs
                kpos = 0
                while kpos < len(max_key) and max_key[kpos] != '\t':
                    kpos += 1
                new_a = max_key[:kpos]
                new_b = max_key[kpos + 1:]
                tr[i] = new_a
                tr[i + 1] = new_b

            i += 1
        t += 1

    # --- emit CSV rows ---
    out = []
    t = 0
    while t < len(trs):
        out.append(_join_csv_row(trs[t]))
        t += 1
    return out

def _levenshtein(a: str, b: str) -> int:
    if len(a) < len(b):
        tmp = a; a = b; b = tmp
    # now len(a) >= len(b)
    prev = [0] * (len(b) + 1)
    j = 0
    while j <= len(b):
        prev[j] = j
        j += 1
    i = 1
    while i <= len(a):
        cur0 = i
        j = 1
        while j <= len(b):
            cost = 0 if a[i-1] == b[j-1] else 1
            ins = cur0 + 1
            dele = prev[j] + 1
            subs = prev[j-1] + cost
            cur = ins if ins < dele else dele
            if subs < cur:
                cur = subs
            prev[j-1] = cur0
            cur0 = cur
            j += 1
        prev[len(b)] = cur0
        i += 1
    return prev[len(b)]

# Greedy segmentation fallback (fallback may not have same outputs as the alternative):
# At position i, pick motif m minimizing ED(seq[i : i+len(m)], m); advance by len(m).
# Emits:
#   - encoded symbol string (lowercase letters etc. as supplied by caller)
#   - CSV of motif strings (DEC row)
def dp_decompose_greedy(seq: str, symbol_to_motif: Dict[str, str]):
    n = len(seq)
    encoded_syms = ""
    dec_csv_parts: List[str] = []
    i = 0
    # Precompute motif list for deterministic order
    syms: List[str] = []
    for k in symbol_to_motif:
        syms.append(k)
    # simple stable sort
    a = 0
    while a < len(syms) - 1:
        b = a + 1
        while b < len(syms):
            if syms[b] < syms[a]:
                tmp = syms[a]; syms[a] = syms[b]; syms[b] = tmp
            b += 1
        a += 1

    while i < n:
        best_sym = ""
        best_mot = ""
        best_cost = 1_000_000
        sidx = 0
        while sidx < len(syms):
            s = syms[sidx]
            m = symbol_to_motif[s]
            L = len(m)
            # slice; if near end, compare against the remaining tail
            end = i + L
            if end > n:
                end = n
            chunk = seq[i:end]
            # compare; if chunk shorter than motif, distance accounts for tail inserts
            c = _levenshtein(chunk, m)
            if c < best_cost:
                best_cost = c
                best_sym = s
                best_mot = m
            sidx += 1
        # append choice
        encoded_syms = encoded_syms + best_sym
        dec_csv_parts.append(best_mot)
        i += len(best_mot)  # advance by motif length (greedy)
        # safety: if motif somehow empty (shouldn't), break
        if len(best_mot) == 0:
            break

    # join DEC CSV
    dec_csv = ""
    j = 0
    while j < len(dec_csv_parts):
        if j > 0:
            dec_csv = dec_csv + ","
        dec_csv = dec_csv + dec_csv_parts[j]
        j += 1
    return (encoded_syms, dec_csv)

